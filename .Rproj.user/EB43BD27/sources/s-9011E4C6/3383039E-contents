---
title: 'LCMS Joint Workflow pos'
author: "Sergio Oller and Luis Fernandez"
date: '2019-07-01'
output:
  html_document:
    code_folding: hide
    df_print: paged
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Pipeline preparation

```{r}
output_dir <- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/HepG2_output"
input_dir <- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/HepG2_dataset/20190313_Lumos_Samples/Data/converted" # where samples are
```


```{r libraries, include = TRUE, eval = TRUE, echo = FALSE}
suppressPackageStartupMessages({
  library(NIHSlcms)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(IPO)
  library(MAIT)
})
```


# NODE 1: Data wrangling

## Convert RAW to mzXML

Samples in RAW format are not easy to convert to mzXML, as we depend on a proprietary tool from Thermo Fisher. We have implemented a function that installs the required tools `install_RawConverter` and a function able to do the conversion. It may be worth checking if there is a more robust solution in other teams at NIHS. Note: Problems with the antivirus system detected at IBEC when installing `MSFileReader` .

```{r raw-to-mzxml}

list_mzxml_samples <- function(sample_path, file_format = "raw", rawconverter){
  
  if (file_format == "raw") {
    #install_RawConverter(rawconverter)
    samples_raw <- fs::dir_ls(sample_path, glob = "*.raw")
    future::plan(multiprocess)
    lcms_raw_to_mzxml(samples = samples_raw, rawconverter = rawconverter)
    future::plan(sequential)
    sample_names_mzxml <- fs::path_abs(fs::dir_ls(sample_path, glob = "*.mzXML"))
  } else if(file_format == "mzXML") {
    sample_names_mzxml<- fs::path_abs(fs::dir_ls(sample_path, glob = "*.mzXML"))
  } else {
    stop("Not allowed file format. Use only either *.raw or *.mzMXML files")
  }
   sample_names_mzxml
}

# path <- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/HepG2_dataset/20190313_Lumos_Samples/Data"
# rawconverter <- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/HepG2_dataset/20190313_Lumos_Samples/Data/converted"
# samples_mzxml <- list_mzxml_samples(path, file_format = "mzXML",
#                                     rawconverter = rawconverter)

```


```{r}
# output_dir_node1 <- file.path(output_dir, "01-load-samples")
# fs::dir_create(output_dir_node1)

# rawconverter <- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/HepG2_dataset/20190313_Lumos_Samples/Data/converted"
samples_mzxml <- list_mzxml_samples(input_dir, # converted samples directory
                                    file_format = "mzXML",
                                    rawconverter = rawconverter)
```


## Load Samples

Our package provides a brief description of the dataset that just has been loaded:
```{r}
not_dia_samples <- samples_mzxml[!grepl(pattern = "_dia.mzXML$", x = samples_mzxml)]
dataset <- lcms_read_samples(not_dia_samples, mode = "onDisk")
print(dataset)
```

## Load metadata

We must tidy the metadata, currently on an excel file:

```{r tidy-metadata}
# lmcs_tidy_metadata <- function(samples_mzxml, metadata_xls, range_xls){
#   
#     basic_meta <- tibble::tibble(sampleNames = base::basename(samples_mzxml)) %>%
#                   dplyr::mutate(sampleNumber = as.numeric(stringr::str_extract(.data$sampleNames, "[0-9]+")),
#                                 DIA = grepl("dia", .data$sampleNames))
# 
#     additional_metadata <- readxl::read_excel(metadata_xls, range = range_xls) %>%
#                           dplyr::rename(sampleNumber = `sample number`) 
# 
#     metadata <- left_join(basic_meta, additional_metadata, by = "sampleNumber")
#     metadata
# }
# 
# metadata_excel<- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/HepG2_dataset/20190313_Lumos_Samples/20190313_DATA_IBEC_sample_key.xlsx"
# range_excel = "A2:C20"
# metadata <- lmcs_tidy_metadata(not_dia_samples, metadata_xls = metadata_excel, range_xls = range_excel)
```

Tidy metadata is easy to add:

```{r add-metadata}
metadata<- readxl::read_excel("C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/HepG2_dataset/20190313_Lumos_Samples/20190313_DATA_IBEC_sample_key.xlsx")

dataset <- NIHSlcms::lcms_meta_add(dataset, metadata, by = "sampleNames")
pData(dataset)
```

It is necessary to associate sample treatments to a color code to help data visualization along the workflow: 
```{r}
treatment_col <- scales::hue_pal()(length(unique(dataset$treatment)))
names(treatment_col) <- unique(dataset$treatment)
treatment_col
```


## Split polarities

The experimental setup is using fast polarity switching, polarities are written interleaved in the data file.
We start by filtering the polarities.

*Note: We wrote the `filterPolarity` function and [submitted it](https://github.com/lgatto/MSnbase/issues/388)
to the MSnbase where it belongs. Once Bioconductor 3.9 is released, the MSnbase will provide this function
and we won't need to include it in our package.*

```{r}
dataset_pos <- filterPolarity(dataset, polarity. = 1)
```


```{r}
output_dir_node2 <- file.path(output_dir, "02-positive-mode")
fs::dir_create(output_dir_node2)

positive_dataset_rds <- fs::path(output_dir_node2, "positive_dataset.rds")
lcms_dataset_save(dataset_pos, positive_dataset_rds)
lcms_meta_export(dataset_pos, fs::path(output_dir_node2, "metadata.xlsx"))
```


# Data exploration 

In this section we show the Total Ion Count (TIC) for the polarity samples. Additionally, we present the boxplots for the TICs according to their sample treatment. Function `lcms_tics` stores summarizes all this information. NOTE: `lcms_tics` assumes that data is already filtered by polarity.
Let's plot here the TIC by sample:

```{r tic-data-frame}
tics_pos <- lcms_tics(dataset_pos)
lcms_plot_tics(tics_pos, rt = c(4, 14), plot_type = "spec") 
lcms_plot_tics(tics_pos, rt = c(4, 14), plot_type = "boxplot")
```



# **Filtering Data**


Examples of data filtering are given.
We filter by:
  * Polarity
  * Sample / Sample type
  * File name


## Filter by retention time / m/z

`New`: Time is measured in minutes. We to this for coherence. `XCMS` and `IPO` packages work in seconds by default, while `CAMERA` and `MAIT` in minutes. Under the hood, the still do in this way, but we preset all our results in minutes. 

```{r}
dataset_pos <- filterRTmin(dataset_pos, rt = c(4, 14))
```


## Filter by sample treatment 

We have realized that not excluding blank samples causes bad retention times aligmnents (Automatized), so they must be removed. `NEW`: Filtering by sample type now is robust. 

You can distinguish and filter different samples types:
  * Regular samples
  * Blank samples
  * Quality Control samples
```{r}
# Wrapped

# filterSampleType <- function(dataset,  especial_samples){
#   
#   qc_label <- especial_samples$qc
#   blank_label <- especial_samples$blank
# 
#   qc_index <- which(dataset$treatment == qc_label)
#   if (length(qc_index) == 0){
#      qcs <- NULL
#   } else{
#      qcs <- filterFile(dataset,file = qc_index) 
#   }
#   
# 
#   blank_index <- which(dataset$treatment == blank_label)
#   if (length(blank_index) == 0){
#     blanks <- NULL
#   } else{
#     blanks <- filterFile(dataset,file = blank_index) 
#   }
# 
#   sample_index <- which(!(dataset$treatment %in% c(qc_label, blank_label)))
#   if (length(sample_index) == 0){
#     regular_samples <- NULL
#     stop("Your dataset doesn't have any sample not considered Blank or QC sample")
#   } else{
#     regular_samples <- filterFile(dataset, file = sample_index) 
#   }
# 
#   datasets_by_class_type <- list(regular_samples = regular_samples, 
#                                  qcs = qcs, blanks = blanks)      
#   
# }

# especial_samples <-list(qc = "DMSO-Ctrl", blank = "blank")
# dataset_pos_by_class_type <- filterSampleType(dataset_pos, especial_samples)
# 
# dataset_pos_no_blanks <-dataset_pos_by_class_type$regular_samples
# dataset_pos_blanks <- dataset_pos_by_class_type$blanks
# dataset_pos_qcs <- dataset_pos_by_class_type$qcs
#To be upgraded: we need to distinguish between datasets and void dummy variables in order to 
# use properly the function pData on the data:
```


```{r}
dataset_pos_by_class_type <- filterSampleType(dataset_pos, especial_samples = NULL)
```


# Parameter optimization

We perform parameter optimization on the XCMS preprocessing algorithms using the `IPO` Package. This includes Peak Detection ('Centwave' and 'Matched Filter', although we only use 'Centwave' method), Retention Time  Correction ('obiwarp') and Peak Correspondence ('Density'). Optimization can be done using all the regular samples(exhaustive), or just a subset. Also you can use Quality Control samples for optimization. Finally, you can skip the optimization process and use the default set of parameter provided by the `IPO` Package.


## Optimization of Peak Detection parameters
First, we have defined a function for obtaing the default set of paramenters:
```{r}
#wrapped

# lcms_default_peakpeaking_params <- function(noise = 5000, snthresh = 10, min_peakwidth = c(10, 30), max_peakwidth = c(35, 90), optimize = TRUE){
#   if (optimize == TRUE){
#     peakpickingParameters <- getDefaultXcmsSetStartingParams(method = c("centWave"))
#     peakpickingParameters$noise <- noise
#     peakpickingParameters$snthresh <- snthresh
#     peakpickingParameters$min_peakwidth <- min_peakwidth
#     peakpickingParameters$max_peakwidth <- max_peakwidth
#   } else{
#     peakpickingParameters <- NULL
#   }
#    peakpickingParameters
# }
```

Using this set of initial parameters the optimization may be started. However, in this particular case, we have selected the input argument _optimize_ as FALSE, so we have skipped the optimization process.


```{r}
output_dir_node3 <- file.path(output_dir, "03-optimization")
fs::dir_create(output_dir_node3)
setwd(output_dir_node3)

# lcms_peakpicking_optimization <- function (dataset, peakpickingParameters,  opt_path){
#   
#   if(is.null(peakpickingParameters)){
#     resultPeakpicking <- NULL
#   } else{
#   filenames <- pData(dataset)$sampleNames
#   filer <- filenames
#   
#   ## Get the spectra
#   data_subset <- dataset %>% MSnbase::filterFile(file = filenames)
#   Biobase::fData(data_subset)$centroided <- TRUE
#   Biobase::fData(data_subset)$peaksCount <- Biobase::fData(data_subset)$originalPeaksCount
#   print("Be aware: do not run twice using the same output directory")
#   mzR::writeMSData(data_subset, file = filer, outformat = c("mzxml"), copy = FALSE)
#   
#   print("Saving filtered spectra...")
# 
#   samples_op <- fs::dir_ls(opt_path , glob = "*.mzXML")
#   print("Performing peak detection parameter optimization. This will take some time...")
#   time.xcmsSet <- system.time({ # measuring time
#   base::suppressWarnings(
#         base::suppressMessages(
#             resultPeakpicking <- optimizeXcmsSet(files =  samples_op, 
#                                            params = peakpickingParameters, 
#                                            nSlaves = 1, 
#                                            subdir = NULL,
#                                            plot = TRUE)
#                            )
#                       )
# })
#   }
# resultPeakpicking 
# }

default_peakpeaking_params <- lcms_default_peakpeaking_params(optimize = TRUE)

resultPeakpicking<- lcms_peakpicking_optimization(dataset_pos, 
                                          default_peakpeaking_params,
                                          nSlaves = 1,
                                          output_dir_node3, plots = TRUE)
                                          
```



Peak optimization results are stored in the variable `optimizedXcmsSetObject`

```{r}
optimizedXcmsSetObject <- resultPeakpicking$best_settings$xset
```




## Optimization of retention time correction and grouping parameters:

```{r}
setwd(output_dir_node3)

# lcms_default_corgroup_params <- function(profStep = 1, gapExtend = 2.7, optimize = TRUE){
#   
#   if (optimize == TRUE){
#     retcorGroupParameters <- getDefaultRetGroupStartingParams()
#     retcorGroupParameters$profStep <- profStep
#     retcorGroupParameters$gapExtend <- gapExtend
#   } else{
#     retcorGroupParameters <- NULL
#   }
#    retcorGroupParameters
# }


# lcms_corgroup_optimization <- function (optimizedXcmsSetObject, retcorGroupParameters, nSlaves = 4, plots = TRUE){
#   
#   if(is.null(optimizedXcmsSetObject) | is.null(retcorGroupParameters)){
#     resultRetcorGroup <- NULL
#   } else{
#   print("Performing retention time and grouping 
#         parameter optimization. This will take some time...")
#   time.RetGroup <- system.time({ # measuring time
#       base::suppressWarnings(
#         base::suppressMessages(
#             resultRetcorGroup <-
#                 optimizeRetGroup(xset = optimizedXcmsSetObject, 
#                                  params = retcorGroupParameters, 
#                                  nSlaves = nSlaves, 
#                                  subdir = "plot_ipo",
#                                  plot = plots)#plot = plot
#                               )
#                             )
#   })
#   }
# resultRetcorGroup
# }
 retcorGroupParameters <- lcms_default_corgroup_params(optimize = TRUE)
 resultRetcorGroup  <- lcms_corgroup_optimization(optimizedXcmsSetObject, retcorGroupParameters, nSlaves = 1)

```


## Displaying and Storing optimized settings

`IPO` Package allows visulizing the parameter optimization results in the RStudio console. Also you can save this results in plain text files (i.e. a .CVS file).

```{r}
# wrapped
# write_opt_params<- function(results_pp, results_rtcg, 
#                             opt_result_path, csv = TRUE, 
#                             console = TRUE ){
#   if (is.null(results_pp) | is.null(results_rtcg)){
#     paramsPP <- list()
#     paramsPP$min_peakwidth <- 20
#     paramsPP$max_peakwidth <- 50
#     paramsPP$ppm <- 25
#     paramsPP$mzdiff <- -0.001
#     paramsPP$snthresh <- 10
#     paramsPP$noise <- 0
#     paramsPP$prefilter <- 3
#     paramsPP$value_of_prefilter <- 100
#     paramsPP$mzCenterFun <-"wMean"
#     paramsPP$integrate <- 1
#     paramsPP$fitgauss <-FALSE
#     paramsPP$verbose.columns <- FALSE
# 
#     paramsRTCGroup <- list()
#     paramsRTCGroup$retcorMethod = "obiwarp"
#     paramsRTCGroup$plottype = "none"
#     paramsRTCGroup$profStep <- 1
#     paramsRTCGroup$center <-  NULL
#     paramsRTCGroup$response <- 1
#     paramsRTCGroup$distFunc <- "cor_opt"
#     paramsRTCGroup$gapInit <- NULL
#     paramsRTCGroup$gapExtend <- NULL
#     paramsRTCGroup$factorDiag <- 2
#     paramsRTCGroup$factorGap <- 1
#     paramsRTCGroup$localAlignment <- 0
#     paramsRTCGroup$initPenalty <- 0
#     
#     paramsRTCGroup$bw <- 30
#     paramsRTCGroup$minfrac <- 0.5
#     paramsRTCGroup$minsamp <- 1
#     paramsRTCGroup$max <- 50
#     paramsRTCGroup$mzwid <- 0.25
#   
#   } else{
#   paramsPP <- results_pp$best_settings$parameters
#   paramsRTCGroup <- results_rtcg$best_settings
#     
#   }
# 
#   
#   if (console == TRUE){
#     writeRScript(paramsPP, paramsRTCGroup)
#   }
#   if (csv == TRUE){
#     writeParamsTable(paramsPP, paramsRTCGroup, 
#                      sep = ",", paste0(opt_result_path, "/params.csv"))
#   }
# }


# output_dir_node3 <- file.path(output_dir, "03-optimization")
# fs::dir_create(output_dir_node3)
# setwd(output_dir_node3)

# opt_result_path <- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/Luis/result"  

IPO_params = write_opt_params(resultPeakpicking, resultRetcorGroup, output_dir_node3)
```


Conversion from `IPO` to `XCMS` variable formats: The variable names in IPO and XCMS presented some mismatches, thus we had to create a function called *IPO_to_XCMS* to achieve compatibility between packages.

```{r optimized-Parameters-to-XCMS}
# IPO_to_XCMS <- function(opt_result_path){
#   params <- utils::read.csv(paste0(opt_result_path, "/params.csv"), stringsAsFactors = FALSE)
#   preproc_params <- list(ppm = params$ppm,
#                          peakwidth = c(params$min_peakwidth, params$max_peakwidth),
#                          snthresh = as.numeric(params$snthresh),
#                          prefilter = c(params$prefilter, params$value_of_prefilter), 
#                          mzCenterFun = params$mzCenterFun, 
#                          integrate =  params$integrate, 
#                          mzdiff = params$mzdiff,
#                          fitgauss = params$fitgauss,
#                          noise = params$noise,
#                          verbose.columns = params$verbose.columns,
#                          profStep = as.numeric(params$profStep),
#                          centerSample = params$center,
#                          response = as.numeric(params$response), 
#                          distFun = params$distFunc,
#                          gapInit = as.numeric(params$gapInit),
#                          gapExtend = as.numeric(params$gapExtend),
#                          factorDiag = as.numeric(params$factorDiag), 
#                          factorGap = as.numeric(params$factorGap), 
#                          localAlignment = as.logical(params$localAlignment),
#                          initPenalty = 0,
#                          bw = as.numeric(params$bw),
#                          minFraction = as.numeric(params$minfrac),
#                          minSamples = as.numeric(params$minsamp),
#                          maxFeatures = as.numeric(params$max),
#                          mzwid = as.numeric(params$mzwid))
#   preproc_params
#   
# }
# opt_result_path <- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/Luis/result"  #repeated by convenience
# preproc_params <- read_IPO_to_XCMS(output_dir_node3)

preproc_params=read_IPO_to_XCMS(output_dir_node3)

```


# Data Preprocessing 

Data Preprocessing is based on the XCMS Package. It includes:

  * Peak Detection
  * Retention Time Correction
  * Peak Correspondence
  * Imputation

Although Data Preprocessing can be performed using any filepath with the `XCMS` Package, it is convenient to rearrange data files by sample class (that is, all the samples belonging to the same sample class are included in the same folder). We do this because, after the Preprocessing stage, the `MAIT` Package takes care of Data Annotation and Metabolite Identification. `MAIT` needs a specific directory structure for data managing. Otherwise, it can't work properly. In the current version of the pipeline we need to include metadata again. `Note`: This is redudant and as to be solved.


```{r To-file-by-class}
output_dir_node4 <- file.path(output_dir, "04-XCMS")
fs::dir_create(output_dir_node4)
# dataDir <- "C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/Luis/dataDir"
# dir.create(dataDir)

# Note: I'd better to create a function to arrange the data
# no_blank_files <- pData(dataset_pos)$sampleNames 
# no_blank_files_treatment <- pData(dataset_pos)$treatment
# 
# filetreat_info <- data.frame(Filename = no_blank_files, 
#                              Treatment= no_blank_files_treatment, 
#                              stringsAsFactors = FALSE) 
# filetreat_info <- filetreat_info %>% group_by(Treatment) %>% arrange(Treatment)
# filetreat_info <- split(filetreat_info, filetreat_info$Treatment)
# 
# drop_treatment <-function(x) {
#                   x$Treatment <- NULL
#                   colnames(x) <- "FileName"
#                   x
#                   }
# 
# filetreat_info <- lapply(filetreat_info, FUN = drop_treatment)

# # Note: I'd better to create a function to write files
# for (i in seq_along(filetreat_info)){
#   filer <- filetreat_info[[i]][["FileName"]]
#   foldname <-names(filetreat_info)[i]
###################################################
#   treatDir <- paste0(dataDir, "/", foldname, "/")
#   dir.create(treatDir)
#   data_subset <- dataset_pos_no_blanks %>% MSnbase::filterFile(file = filer)
#   Biobase::fData(data_subset)$centroided <- TRUE
#   Biobase::fData(data_subset)$peaksCount <- Biobase::fData(data_subset)$originalPeaksCount
#   mzR::writeMSData(data_subset, 
#                    file = unlist(lapply(treatDir, FUN = paste0, filer)), 
#                    outformat = c("mzxml"), copy = FALSE)
# }


rearrange_datafiles_by_class(dataset_pos, dataDir = output_dir_node4)
```


```{r extra-param-xcms-mait, echo:FALSE}
project <- "LUMOS"
dataDir = output_dir_node4
fileList <- list.files(path = paste(dataDir, list.files(path = dataDir), 
                                      sep = "/"), full.names = TRUE)
```


```{r metadata-again, echo:FALSE}
dataset <- lcms_read_samples(fileList, mode = "onDisk")
# basic_meta <- tibble::tibble(sampleNames = base::basename(no_blank_files)) %>%
              dplyr::mutate(sampleNumber = as.numeric(stringr::str_extract(.data$sampleNames, "[0-9]+")),
                DIA = grepl("dia", .data$sampleNames))

# metadata <- readxl::read_excel("C:/Users/fmadrid/Documents/IBEC/NESTLE/LCMS/HepG2_dataset/20190313_Lumos_Samples/20190313_DATA_IBEC_sample_key.xlsx"
#                       range = "A3:C21") %>%
#                     dplyr::rename(sampleNumber = `sample number`)

# full_metadata <- left_join(basic_meta, metadata, by = "sampleNumber")
dataset <- NIHSlcms::lcms_meta_add(dataset, metadata, by = "sampleNames")
```

## Peak Detection:

Our standard method for peak detection is *'CentWave'*, since the data provided was Centroided. We must initialize its parameters according to the `IPO` Package optimization. Peak detection aims to detect important features (peaks) on the chromatographic axis. This will be useful for a posterior peak alignment on the chormatophic axis. *Note: Should we include and optimization for 'Matched Filter' method?

```{r peak-detection, message=FALSE, warning=FALSE}
#wrapped
  # cwp <- xcms::CentWaveParam(peakwidth = preproc_params$peakwidth, 
  #                            ppm = preproc_params$ppm, 
  #                            mzdiff = preproc_params$mzdiff,
  #                            snthresh =  preproc_params$snthresh, 
  #                            noise = preproc_params$noise,
  #                            prefilter = preproc_params$prefilter,
  #                            mzCenterFun = preproc_params$mzCenterFun,
  #                            integrate = preproc_params$integrate,
  #                            fitgauss = preproc_params$fitgauss,
  #                            verboseColumns = preproc_params$verbose.columns) 
  # peakdet_pos_no_blanks <- xcms::findChromPeaks(dataset, param = cwp)

peakdet_pos_no_blanks = findChromPeaks_cwp (dataset_pos_by_class_type$regular_samples, params = preproc_params)

```


## Retention Time Correction:

Retention time correction is performed  using *'obiwarp'* method. Its optimum parameters are obtaine from `IPO` Package. Once the chromatographic peaks are aligned they need to be grouped, as we will see in the next subsection. 

```{r rt-adjustRtime, message=FALSE, warning=FALSE}
  # obiwarp_params <- xcms::ObiwarpParam(binSize = preproc_params$profStep,
  #                                      centerSample = preproc_params$centerSample,
  #                                      response = preproc_params$response,
  #                                      distFun = preproc_params$distFun, 
  #                                      gapInit = preproc_params$gapInit,
  #                                      gapExtend = preproc_params$gapExtend,
  #                                      factorDiag = preproc_params$factorDiag, 
  #                                      factorGap = preproc_params$factorGap, 
  #                                      localAlignment = preproc_params$localAlignment,
  #                                      initPenalty = preproc_params$initPenalty)
  # peakdet_pos_align_no_blanks <- xcms::adjustRtime(peakdet_pos_no_blanks, param = obiwarp_params)

peakdet_pos_align_no_blanks = align_Rtime(peakdet_pos_no_blanks, params = preproc_params)
```


Here, we show the retention time correction againts the original retetion time plot for all of the samples: 

```{r warping-time-correction}
min2sec <- 60
rtc_df <-  tibble::tibble(
    fileIdx = fData(peakdet_pos_align_no_blanks)$fileIdx,
    treatment = pData(peakdet_pos_align_no_blanks)$treatment[fileIdx],
    ret_time_adj = MSnbase::rtime(peakdet_pos_align_no_blanks, adjust = TRUE),
    ret_time_orig = MSnbase::rtime(peakdet_pos_align_no_blanks, adjust = FALSE)
)
rt <- round(base::range(rtc_df$ret_time_orig) / min2sec)
tick_values <- seq(from = rt[1], to = rt[2], by = 2)

ggplot(rtc_df) +
 geom_line(aes(x = ret_time_orig / min2sec, y = (ret_time_adj-ret_time_orig), color = treatment, group = fileIdx)) +
  scale_x_continuous("Original retention time (min.)", limits = rt, breaks = tick_values) + #limits = rt, breaks = tick_values
  scale_y_continuous("Retention time correction (s)") +
  ggtitle("Retention time alignment warping for each sample")
```


## Peak Correspondence:

Peak correspondence is carried out by the *'groupChromPeaks'* method, with parameters obtained form `IPO`. Peak Correspondece consist in grouping peaks on retention time axis with the purspose of associate them to spectra on the mass/chage axis. After this stage we finally have a peak table.

```{r message=FALSE, warning=FALSE}
  pdp <- xcms::PeakDensityParam(sampleGroups = peakdet_pos_align_no_blanks$treatment,
                                binSize = preproc_params$mzwid,  
                                minFraction = preproc_params$minFraction, 
                                minSamples = preproc_params$minSamples,
                                maxFeatures =preproc_params$maxFeatures,
                                bw = preproc_params$bw)
  peak_table_pos <- xcms::groupChromPeaks(peakdet_pos_align_no_blanks, param = pdp)
```

## Plots and results:

The peak table:

```{r peaktable, message = FALSE, warning = FALSE}
tibble::as.tibble(xcms::featureValues(peak_table_pos, value = "into"), rownames = "PeakID")
```

Each feature is described with the range where it fits:

```{r}
tibble::as.tibble(xcms::featureDefinitions(peak_table_pos), rownames = "PeakID")
```

Base peak chromatograms before and after retention time aligment and grouping. Again, we modified the plot measuring the retention time axis in minutes:

```{r plot-base-peak-chromatogram, message = FALSE, warning = FALSE}
#wrapped

# lcms_plotChrom <- function (chromatogram,treatment_col, rtlim = NULL){
#   min2sec <- 60
# 
#   #we need to modify this in order to be more flexible (treatment_col)
#   ret_times <- lapply(chromatogram, FUN = rtime)
#   intensities <- lapply(chromatogram, FUN = intensity)
# 
#   plot(ret_times[[1]] / min2sec, intensities[[1]], type = "l",
#        col = treatment_col[chromatogram$treatment][1], lwd = 1,
#        xlab = "Retention time (min)", ylab = "Intensity  (A.U)",
#        xlim = rtlim,
#        main = "Base Peak Chromatogram")
# 
#   for (i in 2:length(ret_times)){ # we need to modify the sequence using seq_along
#     points(ret_times[[i]] / min2sec, intensities[[i]], lwd = 1,
#           xlim = rtlim,
#           type= "l", col = treatment_col[chromatogram$treatment][i])
#     legend("topright", legend = names(treatment_col), fill = treatment_col)
#   }
# }

```

Chromatogram of the detected peaks per sample **before** time alignment and grouping:
```{r}
rtlim <- c(4, 14)
base_peaks_pos <- xcms::chromatogram(dataset_pos, aggregationFun = "max")
lcms_plotChrom(base_peaks_pos, treatment_col,rtlim = rtlim)
```

Chromatogram of the detected peaks per sample **after** time alignment and grouping:
```{r}
rtlim <- c(13, 13.5)
# no_blanks <- !(names(treatment_col) %in% as.character(unlist(especial_samples))) 
base_peakdet_pos_align_no_blanks  <- xcms::chromatogram(peakdet_pos_align_no_blanks,
                                                         aggregationFun = "max")
lcms_plotChrom(base_peakdet_pos_align_no_blanks, treatment_col, rtlim = rtlim)
```

The base peak chromatograms can be represeted a images as well. This visualization helps the user to evaluate the quality of the aligment:
```{r Image-Detected-Peaks, message = FALSE, warning = FALSE}
plotChromPeakImageRTmin <- function (x, binSize = 30, xlim = NULL, log = FALSE, xlab = "retention time",
  yaxt = par("yaxt"), main = "Chromatographic peak counts",
  ...)
{
  min2sec <- 60
  if (!is(x, "XCMSnExp"))
    stop("'x' is supposed to be an 'XCMSnExp' object, but I got a ",
      class(x))
  if (is.null(xlim))
    xlim <- c(floor(min(rtime(x))), ceiling(max(rtime(x))))
  brks <- seq(xlim[1], xlim[2], by = binSize)
  if (brks[length(brks)] < xlim[2])
    brks <- c(brks, brks[length(brks)] + binSize)
  pks <- chromPeaks(x, rt = xlim)
  if (nrow(pks)) {
    rts <- split(pks[, "rt"], pks[, "sample"])
    cnts <- lapply(rts, function(z) {
      hst <- hist(z, breaks = brks, plot = FALSE)
      hst$counts
    })
    n_samples <- length(fileNames(x))
    sample_idxs <- 1:n_samples
    sample_idxs <- sample_idxs[!(as.character(sample_idxs) %in%
      names(rts))]
    if (length(sample_idxs)) {
      all_cnts <- vector("list", n_samples)
      all_cnts[as.numeric(names(cnts))] <- cnts
      zeros <- rep(0, (length(brks) - 1))
      all_cnts[sample_idxs] <- list(zeros)
      cnts <- all_cnts
    }
    cnts <- t(do.call(rbind, cnts))
    if (log)
      cnts <- log2(cnts)
    image(z = cnts, x = (brks - (brks[2] - brks[1])/2) / min2sec, xaxs = "r",
      xlab = xlab, yaxt = "n", ...)
    if (yaxt != "n")
      axis(side = 2, at = seq(0, 1, length.out = n_samples),
        labels = basename(fileNames(x)), las = 2)
  }
}

```

Image plot of the chromatographic detected peaks per sample **before**  retention time alignment and grouping:
```{r}
plotChromPeakImageRTmin(peakdet_pos_no_blanks, binSize = 5, xlim = NULL, log = FALSE,
  xlab = "retention time (min)", yaxt = par("yaxt"))
title(main ="Detected Peaks (Not Aligned)")
```

Image plot of the chromatographic detected peaks per sample **after**  retention time alignment and grouping:
```{r}
plotChromPeakImageRTmin(peakdet_pos_align_no_blanks, binSize = 5, xlim = NULL, log = FALSE,
  xlab = "retention time (min)", yaxt = par("yaxt"))
title(main ="Detected Peaks (Aligned)")
```

## Imputation:

Finally, in the imputation stage, we integrate the areas of the missing peaks of the peak table that were not detected in the previous steps of the signal preprocessing workflow. This stage is important to make easier statistical and machine learnig posterior stages. 

```{r message=FALSE, warning=FALSE}
  peak_table_neg <- fillChromPeaks(peak_table_pos) # Imputation of peaks 
```

# Annotation 

`MAIT` Package allows to annotate the peaks of the peak table provided by `XCMS`. This is done in three different stages:

  * Annotation with `CAMERA`
  * Annotation using predefined biotransformation
  * Annotation using the Human Metabolome Database (HMDB)

*Note: The dataset must be converted from and objecto of the XCMS Package to an object of the MAIT Package. You can see how to do it in the following code:

```{r write-param-table, echo = TRUE}
writeParameterTable <- function(listParameters,folder){
    outputTable <- as.matrix(c(unlist(listParameters@sampleProcessing),unlist(listParameters@peakAnnotation),                               unlist(listParameters@peakAggregation),unlist(listParameters@sigFeatures),                                          unlist(listParameters@biotransformations),unlist(listParameters@identifyMetabolites),
                        unlist(listParameters@classification),unlist(listParameters@plotPCA),
                        unlist(listParameters@plotHeatmap)))
    colnames(outputTable) <- c("Value")
    write.csv(file=paste(folder,"MAITparameters.csv",sep="/"),outputTable)
    return(outputTable)
}
```

```{r to-MAIT, message=FALSE, warning=FALSE}
to_MAIT <- function (dataDir = NULL, project = NULL, preproc_params = NULL,  peakTable = NULL){
  
  parameters <- c(dataDir = dataDir, preproc_params)
  
  if (is.null(dataDir)) {
    stop("No input directory was given")
  }
  if (is.null(project)) {
    stop("No project name was included")
  }
  if (is.null(preproc_params)) {
    stop("No parameters for preprocessing were included")
  }
  if (is.null(peakTable)) {
    stop("No peak was included")
  }
  
  MAIT.object <- new("MAIT")
  MAIT.object@RawData@parameters@sampleProcessing <- parameters
  writeParameterTable(parameters(MAIT.object), folder = resultsPath(MAIT.object)) # warning: resultsPath
  class <- list.files(dataDir)
  classNum <- vector(length = length(class))
  fileList <- list.files(path = paste(dataDir, list.files(path = dataDir), 
                                      sep = "/"), full.names = TRUE)
  for (i in 1:length(class)) {
    classNum[i] <- length(list.files(paste(dataDir, list.files(dataDir)[i], 
                                           sep = "/")))
  }
  
  classes <- rep(class, classNum)
  
  if (length(list.files(dataDir)) == 1) {
    warning("Warning: Input data only has one class!")
  }
  if (is.null(project)) {
    warning("Warning: Project name is empty!")
  }
  if (!is.null(project)) {
    resultsPath <- paste("Results", project, sep = "_")
    dir.create(resultsPath)
  }
  else {
    resultsPath <- "Results"
    dir.create(resultsPath)
  }
  
  peakTable <- as(peakTable, "xcmsSet")
  peakTable <- fillPeaks(peakTable)
  fPeaks <- list(peakTable)
  names(fPeaks) <- "xcmsSet"
  MAIT.object@RawData@data <- fPeaks
  MAIT.object@PhenoData@classes <- class
  MAIT.object@PhenoData@classNum <- classNum
  MAIT.object@PhenoData@resultsPath <- resultsPath
  MAIT <- MAIT.object   
}
peak_table_neg_MAIT <- to_MAIT(dataDir, project, preproc_params, peak_table_neg)
```


## Annotation with CAMERA

First annotation is performed by the function *'peakAnnotation'*. This function uses `CAMERA` under the hood. Basically, it uses a peak correlation distance and retention time window to ascertain which peaks come from the same metabolite. Peaks from the same grou are annotated following a reference adduct/table and a mass tolerance window.

```{r MAIT-Annotation, warning=FALSE}
peak_table_neg_ANN <- peakAnnotation(MAIT.object = peak_table_neg_MAIT,
                       corrWithSamp = 0.7,
                       corrBetSamp = 0.75,
                       perfwhm = 0.6)
rawData(peak_table_neg_ANN)
```

Additionally, it is possible to inspect which features are statistically among classes after the first annotatio stage using the function *'spectralSigFeatures'*. This information is stored in .*csv file:

```{r}
peak_table_neg_ANN <- spectralSigFeatures(MAIT.object = peak_table_neg_ANN,
                           pvalue=0.05,
                           p.adj="none",
                           scale=FALSE)
```

```{r summary-1}
summary(peak_table_neg_ANN)
```


The function *'sigPeaksTable'* retrieves the information of the above-mentioned table:

```{r sign-table}
signTable <- sigPeaksTable(MAIT.object = peak_table_neg_ANN, 
                            printCSVfile = FALSE)

```


We have modified the basic Boxplot function from the `MAIT` package in order to generate elegant plots using the `ggplot2` package for the significant features. These Boxplots are colored according to the sample treatment. The results are stored in a folder called _Boxplots_

```{r MAIT-BOXPLOT-function}
 lcms_plotBoxPlot <- function (MAIT.object = NULL, treatment_col) {
   if (is.null(treatment_col)) {
    stop("No input treatment column was given")
  }
  if (is.null(MAIT.object)) {
    stop("No input MAIT object file was given")
  }
  if (length(featureSigID(MAIT.object)) == 0) {
    stop("No significant features found in the MAIT object. Make sure that functions peakAnnotation and peakAggregation were launched")
  }
  data <- scores(MAIT.object)
  index <- featureSigID(MAIT.object)
  class <- classes(MAIT.object)
  classNum <- classNum(MAIT.object)
  resultsPath <- resultsPath(MAIT.object)
  clases <- matrix(nrow = 1)
  for (i in c(1:length(class))) {
    clases <- c(clases, rep(class[i], classNum[i]))
  }
  clases <- clases[-1]
  clases <- as.factor(clases)
  aux <- t(data[index, ])
  if (!file.exists(paste(resultsPath, "Boxplots", sep = "/"))) {
    dir.create(paste(resultsPath, "Boxplots", sep = "/"))
  }else {
    cat(" ", fill = TRUE)
    cat(paste("Warning: Folder", paste(resultsPath, "Boxplots", 
      sep = "/"), "already exists. Possible file overwritting.", 
      sep = " "), fill = TRUE)
  }
  for (i in c(1:length(index))) {
    peaks_df <- data.frame(peaks = aux[,i], 
                           treatment = clases, 
                           stringsAsFactors = FALSE)
    ggplot(peaks_df) + 
    geom_boxplot(aes(x = treatment, y = peaks, fill = treatment)) +
    scale_fill_manual("Treatment", values = treatment_col) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ggtitle(paste("Boxplot of the Spectra", index[i]))
    base::suppressWarnings(
      base::suppressMessages(ggsave(paste(paste(resultsPath, "Boxplots/Boxplot_spectra_", 
      sep = "/"), index[i], ".png", sep = ""))))
  }
}

```

```{r}
 lcms_plotBoxPlot(MAIT.object = peak_table_neg_ANN, treatment_col)
```

We have done the same for the Principal Component Analysis function provided by `MAIT`. Only the Score plot for the first two Principal Components is shown, but in the folder called _PCA_ you can find plots for the loadings and the scores up to the third Principal Component. Also, you will see plot showing the percentage of variance captured by each Principal Component.

```{r MAIT-PCA}
lcms_PCA <- function (MAIT.object = NULL,treament_col, Log = FALSE, center = TRUE, scale = TRUE)
{
  if (is.null(MAIT.object)) {
    stop("No input MAIT object file was given")
  }
    if (is.null(treament_col)) {
    stop("No input treatment column was given")
  }
  if (length(featureSigID(MAIT.object)) == 0) {
    stop("No significant features found in the MAIT object. Make sure that functions peakAnnotation and peakAggregation were launched")
  }
  parameters <- list(Log, center, scale)
  names(parameters) <- c("PCA data logarithm", "PCA data centered", 
    "PCA data scaled")
  MAIT.object@RawData@parameters@plotPCA <- parameters
  writeParameterTable(parameters(MAIT.object), folder = resultsPath(MAIT.object))
  data <- scores(MAIT.object)
  clases <- classes(MAIT.object)
  classNum <- classNum(MAIT.object)
  xsaFA <- MAIT.object@RawData@data
  resultsPath <- resultsPath(MAIT.object)
  index <- featureSigID(MAIT.object)
  cols <- matrix(nrow = 1)
  textCols <- matrix(nrow = 1)
  for (i in 1:length(clases)) {
    cols <- c(cols, rep(i, classNum[i]))
  }
  cols <- as.character(cols[-1])
  textCols <- 1:length(clases)
  if (Log == FALSE) {
    data <- (scale(t(data[index, ]), center = center, scale = scale))
  }else {
    data <- (scale(t(log10(data[index, ] + 1)), center = center, 
      scale = scale))
  }
  if (!file.exists(paste(resultsPath, "PCA", sep = "/"))) {
    dir.create(paste(resultsPath, "PCA", sep = "/"))
  }else {
    cat(" ", fill = TRUE)
    cat(paste("Warning: Folder", paste(resultsPath, "PCA_Results", 
      sep = "/"), "already exists. Possible file overwritting.", 
      sep = " "), fill = TRUE)
  }
      

  model <- prcomp(data)
  var_expl <-100 *((model$sdev ^ 2)/sum(model$sdev ^ 2))
  model_df <- data.frame(pc = seq(1, dim(model$x)[1], by = 1), model$x, 
                         var_expl = var_expl,
                         treatment = clases, 
                         stringsAsFactors = FALSE)
  

  ggplot(model_df) +
  geom_point(aes(x = pc , y = var_expl), color = "blue") +
  scale_x_continuous("Principal Component") + 
  scale_y_continuous("Percentage of Variance (%)") +
  ggtitle(paste("Percentage of Variance per Principal Component"))
  

  base::suppressWarnings(
    base::suppressMessages(ggsave(paste(paste(resultsPath, 
                                              "PCA/Percentage_of_Variance_per_PC.png", 
                                              sep = "/")))))
  
  PC1_PC2_plot  <- ggplot(model_df) + 
                   geom_point(aes(x = PC1, y = PC2, color = treatment)) +
                   geom_hline(yintercept = 0, linetype="dashed", color = "black") +
                   geom_vline(xintercept = 0, linetype="dashed", color = "black") +
                   scale_color_manual("Treatment", values = treatment_col) +
                   scale_x_continuous(paste0("PC1 (", round(model_df$var_expl[1], 2), " %)")) + 
                   scale_y_continuous(paste0("PC2 (", round(model_df$var_expl[2], 2), " %)"))  +
                   ggtitle(paste("PCA Scoreplot", "PC1", "vs", "PC2"))
  print(PC1_PC2_plot)
   base::suppressWarnings(
    base::suppressMessages(ggsave(paste(paste(resultsPath,"PCA/Scoreplot_PC12.png", sep = "/")),
         plot = PC1_PC2_plot)))
  
  loadings_df <- data.frame(model$rotation[, 1:3],
                            feature = 1:dim(model$rotation[, 1:3])[1]) %>% 
                 tidyr::gather(key = "PC", value = "loadings", -feature)
  
  
  ggplot(loadings_df) + 
    geom_line(aes(x = feature, y = loadings, color = PC)) +
    ggtitle(paste("Loadings of the PCA model (3 PCs)")) +
    scale_x_continuous("Signicant Feature Index") + 
    scale_y_continuous("Loadings (adim.)")
    base::suppressWarnings(
      base::suppressMessages(ggsave(paste(paste(resultsPath,
                                                "PCA/Loadings.png", sep = "/")))))
  
  
  ggplot(model_df) + 
  geom_point(aes(x = PC1, y = PC3, color = treatment)) +
  geom_hline(yintercept = 0, linetype="dashed", color = "black") +
  geom_vline(xintercept = 0, linetype="dashed", color = "black") +
  scale_color_manual("Treatment", values = treatment_col) +
  scale_x_continuous(paste0("PC1 (", round(model_df$var_expl[1], 2), " %)")) + 
  scale_y_continuous(paste0("PC3 (", round(model_df$var_expl[3], 2), " %)"))  +
  ggtitle(paste("PCA Scoreplot", "PC1", "vs", "PC3"))
  base::suppressWarnings(
    base::suppressMessages(ggsave(paste(paste(resultsPath,
                                              "PCA/Scoreplot_PC13.png", sep = "/")))))
    
  
  ggplot(model_df) + 
  geom_point(aes(x = PC2, y = PC3, color = treatment)) +
  geom_hline(yintercept = 0, linetype="dashed", color = "black") +
  geom_vline(xintercept = 0, linetype="dashed", color = "black") +
  scale_color_manual("Treatment", values = treatment_col) +
  scale_x_continuous(paste0("PC1 (", round(model_df$var_expl[2], 2), " %)")) + 
  scale_y_continuous(paste0("PC2 (", round(model_df$var_expl[3], 2), " %)"))  +
  ggtitle(paste("PCA Scoreplot", "PC2", "vs", "PC3"))
 base::suppressWarnings(
    base::suppressMessages(ggsave(paste(paste(resultsPath,
                                              "PCA/Scoreplot_PC23.png", sep = "/")))))

  MAIT.object@FeatureData@pcaModel <- list(model)
  return(MAIT.object)
}

peak_table_neg_ANN<-lcms_PCA(peak_table_neg_ANN, 
                             treament_col = treatment_col,
                             Log = FALSE, 
                             center = TRUE, scale = TRUE)

```

## Annotation using predefined biotransformation

The second step uses a mass tolerance window inside the peak groups detected after the annotationf with `CAMERA` step to look for more specfic mass losses (biotransformations). The function *'Biotransformations'* carries out this task.`MAIT`offers a predefined biotransformation table, although users are allowed to generate their own biotransformation table.


```{r Biotransformations, warning=FALSE}
Biotransformations(MAIT.object = peak_table_neg_ANN, 
                     peakPrecision = 0.005)
```

## Annotation using the Human Metabolome Database (HMDB)

The third annotation step is the metabolite identication stage using the function *'identifyMetabolites'*, where the HMDB is mined to search for significant masses using a mass tolerance window.

```{r indentify-metabolites, warning=FALSE}
peak_table_neg_ANN  <- identifyMetabolites(MAIT.object = peak_table_neg_ANN, 
                              peakTolerance = 0.005)
```
